{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e891260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script pour générer des fichiers CSV à partir de données d'images et de segmentations\n",
    "\n",
    "# Chemin vers le dossier racine 7272660\n",
    "ROOT_DIR = os.getcwd() + '/dataset/7272660'\n",
    "\n",
    "# Liste pour stocker les données\n",
    "images_data = []\n",
    "segmentations_data = []\n",
    "\n",
    "# ID incrémentaux simulés\n",
    "current_image_id = 1\n",
    "current_segmentation_id = 1\n",
    "\n",
    "# Les catégories et leurs sous-dossiers\n",
    "CATEGORIES = {\n",
    "    'Benign': 'Benign',\n",
    "    'Malignant': 'Malignant',\n",
    "    'Mormal': 'Normal'\n",
    "}\n",
    "\n",
    "# Parcours des catégories\n",
    "for category_key, category_folder in CATEGORIES.items():\n",
    "    category_path = os.path.join(ROOT_DIR, category_folder, category_folder)\n",
    "\n",
    "    images_path = os.path.join(category_path, 'image')\n",
    "    segmentation_path = os.path.join(category_path, 'segmentation')\n",
    "\n",
    "    # Vérifier que le dossier existe\n",
    "    if not os.path.exists(images_path):\n",
    "        print(f\"Dossier {images_path} manquant.\")\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(images_path):\n",
    "        if file_name.lower().endswith('.jpg'):\n",
    "            # Préparer les infos pour la table image\n",
    "            image_record = {\n",
    "                'id_image': current_image_id,\n",
    "                'file_name': file_name,\n",
    "                'file_path': os.path.relpath(os.path.join(images_path, file_name), ROOT_DIR).replace(\"\\\\\", \"/\"),\n",
    "                'category': category_key\n",
    "            }\n",
    "            images_data.append(image_record)\n",
    "\n",
    "            base_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "            # Pour chaque type de segmentation\n",
    "            for seg_type in ['liver', 'mass', 'outline']:\n",
    "                seg_folder = os.path.join(segmentation_path, seg_type)\n",
    "                seg_file_path = os.path.join(seg_folder, base_name + '.json')\n",
    "\n",
    "                if os.path.exists(seg_file_path):\n",
    "                    # Lecture du contenu JSON\n",
    "                    with open(seg_file_path, 'r', encoding='utf-8') as f:\n",
    "                        annotation_content = json.load(f)\n",
    "\n",
    "                    segmentation_record = {\n",
    "                        'id_segmentation': current_segmentation_id,\n",
    "                        'segmentation_type': seg_type.capitalize(),  # Liver, Mass, Outline\n",
    "                        'annotation': json.dumps(annotation_content),  # pour l'insérer en base\n",
    "                        'fk_id_image': current_image_id\n",
    "                    }\n",
    "                    segmentations_data.append(segmentation_record)\n",
    "                    current_segmentation_id += 1\n",
    "                else:\n",
    "                    # Pas d'erreur si mass manque pour normal par exemple\n",
    "                    if seg_type == 'mass' and category_key == 'normal':\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f\"Annotation {seg_type} manquante pour {file_name}\")\n",
    "\n",
    "            # Incrémenter l'image id\n",
    "            current_image_id += 1\n",
    "\n",
    "# Création des DataFrames\n",
    "df_images = pd.DataFrame(images_data)\n",
    "df_segmentations = pd.DataFrame(segmentations_data)\n",
    "\n",
    "# Sauvegarde en CSV\n",
    "output_images_csv = os.path.join(os.getcwd() + '/output_data/images.csv')\n",
    "output_segmentations_csv = os.path.join(os.getcwd() + '/output_data/segmentations.csv')\n",
    "\n",
    "df_images.to_csv(output_images_csv, index=False, encoding='utf-8')\n",
    "df_segmentations.to_csv(output_segmentations_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"CSV Images généré : {output_images_csv}\")\n",
    "print(f\"CSV Segmentations généré : {output_segmentations_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1a0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_database = duckdb.connect(database='annotated_ultrasound.db', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f6098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_images = pd.read_csv(output_images_csv)\n",
    "dataframe_segmentations = pd.read_csv(output_segmentations_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_database.register('images_dataframe', dataframe_images)\n",
    "connection_database.register('segmentations_dataframe', dataframe_segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_database.execute(\"DROP TABLE IF EXISTS t_image; CREATE TABLE t_image AS SELECT * FROM images_dataframe\")\n",
    "connection_database.execute(\"DROP TABLE IF EXISTS t_segmentation; CREATE TABLE t_segmentation AS SELECT * FROM segmentations_dataframe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
